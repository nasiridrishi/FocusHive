global:
  # SMTP configuration for email alerts
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_from: 'alerts@focushive.com'
  smtp_auth_username: '{{ SMTP_USERNAME }}'
  smtp_auth_password: '{{ SMTP_PASSWORD }}'
  smtp_auth_identity: '{{ SMTP_USERNAME }}'
  smtp_require_tls: true

  # Slack configuration (optional)
  slack_api_url: '{{ SLACK_WEBHOOK_URL }}'

  # Default settings
  resolve_timeout: 5m

# Templates for alert formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route tree for alert routing
route:
  # Default receiver
  receiver: 'team-leads'
  
  # Group alerts by these labels
  group_by: ['alertname', 'severity', 'service']
  
  # Wait time before sending initial alert
  group_wait: 10s
  
  # Wait time before sending batch of new alerts
  group_interval: 10s
  
  # Wait time before resending alert
  repeat_interval: 1h

  # Child routes for specific routing
  routes:
    # Critical alerts go to PagerDuty and email
    - match:
        severity: critical
      receiver: 'critical-alerts'
      continue: true
      
    # Database alerts go to DBA team
    - match_re:
        service: (postgresql|redis)
      receiver: 'database-team'
      group_wait: 30s
      
    # Application alerts
    - match_re:
        service: (backend|identity-service|frontend)
      receiver: 'dev-team'
      
    # Infrastructure alerts
    - match_re:
        alertname: (DiskSpaceLow|ContainerKilled|NodeDown)
      receiver: 'ops-team'
      
    # Low priority alerts
    - match:
        severity: info
      receiver: 'monitoring-channel'
      repeat_interval: 12h

# Receivers configuration
receivers:
  # Default receiver
  - name: 'team-leads'
    email_configs:
      - to: 'team-leads@focushive.com'
        send_resolved: true
        headers:
          Subject: '[FocusHive Alert] {{ .GroupLabels.alertname }} - {{ .GroupLabels.severity }}'
        html: |
          <h2>ðŸš¨ Alert: {{ .GroupLabels.alertname }}</h2>
          <p><b>Severity:</b> {{ .GroupLabels.severity }}</p>
          <p><b>Service:</b> {{ .GroupLabels.service }}</p>
          {{ range .Alerts }}
          <hr>
          <p><b>Summary:</b> {{ .Annotations.summary }}</p>
          <p><b>Description:</b> {{ .Annotations.description }}</p>
          <p><b>Started:</b> {{ .StartsAt }}</p>
          {{ if .EndsAt }}<p><b>Ended:</b> {{ .EndsAt }}</p>{{ end }}
          {{ end }}

  # Critical alerts receiver
  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@focushive.com'
        send_resolved: true
    pagerduty_configs:
      - service_key: '{{ PAGERDUTY_SERVICE_KEY }}'
        description: '{{ .GroupLabels.alertname }}: {{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
    slack_configs:
      - channel: '#critical-alerts'
        title: 'ðŸš¨ CRITICAL: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true

  # Development team receiver
  - name: 'dev-team'
    email_configs:
      - to: 'dev-team@focushive.com'
        send_resolved: true
    slack_configs:
      - channel: '#dev-alerts'
        title: 'Dev Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true

  # Database team receiver
  - name: 'database-team'
    email_configs:
      - to: 'dba@focushive.com'
        send_resolved: true
    slack_configs:
      - channel: '#database-alerts'
        title: 'DB Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'

  # Operations team receiver
  - name: 'ops-team'
    email_configs:
      - to: 'ops@focushive.com'
        send_resolved: true
    slack_configs:
      - channel: '#ops-alerts'
        title: 'Ops Alert: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: true

  # Low priority monitoring channel
  - name: 'monitoring-channel'
    slack_configs:
      - channel: '#monitoring'
        title: 'Info: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
        send_resolved: false

# Inhibition rules to suppress certain alerts
inhibit_rules:
  # If service is down, suppress high CPU/memory alerts for that service
  - source_match:
      alertname: ServiceDown
    target_match_re:
      alertname: (HighCPUUsage|HighMemoryUsage|SlowResponseTime)
    equal: ['service']
    
  # If PostgreSQL is down, suppress connection alerts
  - source_match:
      alertname: PostgreSQLDown
    target_match:
      alertname: PostgreSQLTooManyConnections
    
  # If Redis is down, suppress memory alerts
  - source_match:
      alertname: RedisDown
    target_match:
      alertname: RedisHighMemoryUsage